# *LLM* pour la recherche documentaire

Ce chapitre se concentre uniquement sur les aspects d'intelligence artficielle générative (IAg) pour le repérage de documents. Donc, les outils de cartographie de l'information basés sur les citations (ResearchRabbit, Inciteful, etc.) sont exclus. 

## Cadre général 

- Très souvent, ces outils sont **systèmes complexes** de **boîtes noires opaques** dont il est très difficile de comprendre le fonctionnement. 
  - Selon moi, c'est le problème principal car c'est non-scientifique, non-reproductible, et soumis par nature au bon vouloir de compagnies commerciales.
  - Cela cache tous les biais de ces outils.
  - Combiné avec un style assertif ou sycophantique, cela peut nous induire à accorder plus de confiance envers ces outils.
- Le module génératif de ces systèmes : 
  - a une **capacité de calcul limitée** pour traiter de gros volumes d'information.
  - Par nature, il est conçus pour rédiger du texte statistiquement, calculé par « à quoi **ressemblerait** le meilleur texte après celui celui-ci ? »
- Ces outils ont une tendance à délester l'utilisateur de prises de décision en se substituant à ses jugements critiques. Cela peut induire :
  - moins d'apprentissage, 
  - moins de posture critique, 
  - moins de vérification si la référence existe, 
  - moins de vérification que telle information se trouve bien dans la référence annoncée,
  - bref plus de surévaluation des résultats de l'IAg.

## Deux familles d'outils 

### Outils IAg « généralistes » 

- Exemples : ChatGPT, Copilot, Gemini, Claude.
- Systèmes d'IA complètement emboîtés dans un module génératif : 
  - Même dotés de fonctionnalités de recherche de documents («RAG»), et de fonctionnalités d’encadrement fortes, les modules génératifs dans ces outils produiront [toujours](https://arxiv.org/abs/2509.04664) des informations inexistantes (références ou synthèses/résumés).
  - Même si un référence existe, une information est présentée comme extraite de cette référence :
    - ces outils peuvent rédiger l’information AVANT (à partir du modèle de langue) puis ENSUITE chercher une référence;
    - l’information synthétisée peut être absente de la référence.
  - En octobre 2025, les références inventées sont plus rares dans ChatGPT et Claude, mais les « hallucinations » se sont déplacées dans les fausses informations extraites. 

### Outils IAg « spécialisés » 

- Exemples : Asta.allen.ai; Consensus.app; Elicit.com; Evidencehunt.com; Getliner.com; Keenious.com; Platform.futurehouse.com; SciSpace.com ; Undermind.ai
- Systèmes d'IA fonctionnant comme un module de moteur de recherche, posés sur un corpus de données et qui produisent des synthèses de résultats. 
- Viennent en une ou deux fonctionnalités : 
  - Recherche de documents, présentant des listes de résultats;
  - Production de rapport de synthèse où les résultats sont assemblés dans des paragraphes rédigés.
- Presque pas de références inventées mais « hallucinations » et biais dans les synthèses. 

## Mon enjeu en ce moment (septembre 2025)

- Évaluer quelle est la proportion de texte rédigé qui provient du modèle de langue par rapport à la proportion apportée par les textes censés avoir été repéré. 
  - Hypothèse : étant donnée les capacités de traitement limité, les systèmes IAg rédigent d'abord le texte puis ils saupoudrent de références en les appariant à posteriori. Notre cerveau interprète les résultats comme étant des synthèses logiques du contenu des références trouvées alors qu'il n'en est rien. 
  - Très souvent, il n'est pas possible de faire sa propre sélection de résultats de recherche et de demander une synthèse du tout. Peut être pour qu'on ne discerne pas comment les synthèses sont produites ? 
  - Quand une référence repérée est incorporée dans la synthèse, est-ce son résumé seulement ou le texte intégral qui est utilisé ?

## Documents de soutien

- [BINGO critique de l’IAg pour la recherche de documents](https://boite-outils.bib.umontreal.ca/ld.php?content_id=37726345). Questions à se poser quand on teste un nouvel outil, pour se mettre en mode Évaluation critique et affuter son discernement.
- [Test d’outils IA génératives spécialisés pour la recherche universitaire](https://boite-outils.bib.umontreal.ca/ld.php?content_id=37640268). Plusieurs outils IAg « spécialisés » testés par les Bibliothèques UdeM.
- [Comment déclarer](https://boite-outils.bib.umontreal.ca/c.php?g=743753&p=5377614) son utilisation de l'IAg dans ses travaux (si c'est autorisé car c'est interdit par défaut à l'UdeM)

## Annexe : Petite liste d’habiletés à ne pas trop déléguer aux machines

- Habileté à transcrire une demande d’information en mots -clés, à évaluer la qualité de la demande et à reformuler sa stratégie de recherche (on perd en
rétroaction avec l’outil et le décryptage du fonctionnement est plus complexe ou plus invisible)
- Habileté à évaluer les résultats d’une recherche (avec les outils IAg c’est toujours une petite sélection de résultats dont on ne connaît pas les critères)
- Habileté à prendre la décision de sélectionner un résultat pertinent (les résultats sont présentés et rédigés dans un langage assertif ou d’autorité, où l’outil se substitue au jugement de l’utilisateur).
- Habileté à se construire une image mentale de l’ensemble de la documentation scientifique sur un sujet et comment la conversation scientifique s’articule
entre ceux ceux-ci.
- Habileté à évaluer et extraire l’information pertinente pour soutenir son argumentation.
- Habileté à repérer le niveau d’exhaustivité atteint lors d’une recherche d’information
